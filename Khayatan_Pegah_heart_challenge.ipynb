{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Fa6NRB3hOd",
        "outputId": "070aac5d-0989-4a89-9e3c-b39e41e5ff15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchio\n",
            "  Downloading torchio-0.18.91-py2.py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.8/172.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchio) (4.65.0)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: typer[all] in /usr/local/lib/python3.10/dist-packages (from torchio) (0.7.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.10/dist-packages (from torchio) (2.0.0+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchio) (1.10.1)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from torchio) (3.0.2)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from torchio) (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from torchio) (1.22.4)\n",
            "Collecting SimpleITK!=2.0.*,!=2.1.1.1\n",
            "  Downloading SimpleITK-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.12.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1->torchio) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1->torchio) (16.0.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->torchio) (1.14.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]->torchio) (8.1.3)\n",
            "Collecting shellingham<2.0.0,>=1.3.0\n",
            "  Downloading shellingham-1.5.0.post1-py2.py3-none-any.whl (9.4 kB)\n",
            "Collecting colorama<0.5.0,>=0.4.3\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting rich<13.0.0,>=10.11.0\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<13.0.0,>=10.11.0->typer[all]->torchio) (2.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1->torchio) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1->torchio) (1.3.0)\n",
            "Installing collected packages: SimpleITK, commonmark, shellingham, rich, Deprecated, colorama, torchio\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.3.4\n",
            "    Uninstalling rich-13.3.4:\n",
            "      Successfully uninstalled rich-13.3.4\n",
            "Successfully installed Deprecated-1.2.13 SimpleITK-2.2.1 colorama-0.4.6 commonmark-0.9.1 rich-12.6.0 shellingham-1.5.0.post1 torchio-0.18.91\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 43.0 kB of archives.\n",
            "After this operation, 115 kB of additional disk space will be used.\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.8.0-1_amd64.deb ...\n",
            "Unpacking tree (1.8.0-1) ...\n",
            "Setting up tree (1.8.0-1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install torchio\n",
        "%pip install --quiet torchvision\n",
        "%pip install --quiet matplotlib\n",
        "#!pip install numpy<1.24\n",
        "!apt -qq install tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKM1xi6e3qIU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import enum\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import sklearn\n",
        "import time\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torchio as tio\n",
        "from torch.utils.data import DataLoader\n",
        "import multiprocessing\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import ConcatDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "\n",
        "\n",
        "num_workers = multiprocessing.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(tio.__version__)\n",
        "print(np.__version__)\n",
        "print(matplotlib.__version__)\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw1mEx5mLE5k",
        "outputId": "ac848642-8798-485c-ecc3-effad4da3a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu118\n",
            "0.18.91\n",
            "1.22.4\n",
            "3.7.1\n",
            "1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKdLygn3-c6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785b60b2-154d-4139-f97f-7c19fa422e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May  7 21:03:23 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sonSKodp4Aem",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602cd023-3e41-49a8-91be-b4c57032a9cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[Errno 2] No such file or directory: '/gdrive'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_6ofn1g4EPv"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,\"/content/drive/MyDrive/IMA205/ima205-challenge-2023\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AX1lmGR4GW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3d4cdf-f6f2-444f-b679-d92111db9635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".DS_Store\n",
            "Classif_model.pt\n",
            "SampleSubmission.csv\n",
            "Segmentation_model_.pt\n",
            "Test\n",
            "Train\n",
            "best_models\n",
            "metaDataTest.csv\n",
            "metaDataTrain.csv\n",
            "new_segmentation_models\n",
            "results\n",
            "segmentation_model_ED.pt\n",
            "segmentation_model_ES.pt\n"
          ]
        }
      ],
      "source": [
        "data_path = \"/content/drive/MyDrive/IMA205/ima205-challenge-2023\"\n",
        "\n",
        "\n",
        "for file in sorted(os.listdir(data_path)):\n",
        "  print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFbZBdX14HSs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_meta_train = pd.read_csv(os.path.join(data_path, 'metaDataTrain.csv'))\n",
        "df_meta_test = pd.read_csv(os.path.join(data_path, 'metaDataTest.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcMU0UUM4N_a"
      },
      "outputs": [],
      "source": [
        "training_transform = tio.Compose([\n",
        "    #tio.ToCanonical(),\n",
        "    tio.Resample((1.3, 1.3, 10)),\n",
        "    #tio.RandomMotion(p=0.2),\n",
        "    tio.CropOrPad((300, 300, 10)),\n",
        "    tio.ZNormalization(masking_method=tio.ZNormalization.mean),\n",
        "    #tio.OneHot(),\n",
        "])\n",
        "\n",
        "training_transform_rot = tio.Compose([\n",
        "    #tio.ToCanonical(),\n",
        "    tio.Resample((1.3, 1.3, 10)),\n",
        "    #tio.RandomMotion(p=0.2),\n",
        "    tio.CropOrPad((300, 300, 10)),\n",
        "    tio.ZNormalization(masking_method=tio.ZNormalization.mean),\n",
        "    tio.RandomAffine(degrees=(90, 90)),\n",
        "    #tio.OneHot(),\n",
        "])\n",
        "\n",
        "validation_transform = tio.Compose([\n",
        "    #tio.ToCanonical(),\n",
        "    tio.Resample((1.3, 1.3, 10)),\n",
        "    tio.CropOrPad((300, 300, 10)),\n",
        "    tio.ZNormalization(masking_method=tio.ZNormalization.mean),\n",
        "    #tio.OneHot(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQJqbMxY4PY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5fa2ac-ea83-4adb-f275-39ec5491eb73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 50 subjects\n"
          ]
        }
      ],
      "source": [
        "# create a dataset of first type of mri and the second one\n",
        "def counter(a):\n",
        "  if a >= 100:\n",
        "    return str(a)\n",
        "  elif a < 10:\n",
        "    return '00'+str(a)\n",
        "  else:\n",
        "    return '0'+str(a)\n",
        "\n",
        "\n",
        "subjects_ED = []\n",
        "subjects_ES = []\n",
        "for i in range(101,151):\n",
        "  current_dir = os.path.join(data_path, 'Test', counter(i))\n",
        "  subject_ED = tio.Subject(\n",
        "        mri=tio.ScalarImage(os.path.join(current_dir, counter(i)+'_ED.nii')),\n",
        "        segment=tio.LabelMap(os.path.join(current_dir, counter(i)+'_ED_seg.nii')),\n",
        "        height=df_meta_test.iloc[i-100-1]['Height'],\n",
        "        weight=df_meta_test.iloc[i-100-1]['Weight'],\n",
        "    )\n",
        "  subject_ES = tio.Subject(\n",
        "        mri=tio.ScalarImage(os.path.join(current_dir, counter(i)+'_ES.nii')),\n",
        "        segment=tio.LabelMap(os.path.join(current_dir, counter(i)+'_ES_seg.nii')),\n",
        "        height=df_meta_test.iloc[i-100-1]['Height'],\n",
        "        weight=df_meta_test.iloc[i-100-1]['Weight'],\n",
        "    )\n",
        "\n",
        "  subjects_ED.append(subject_ED)\n",
        "  subjects_ES.append(subject_ES)\n",
        "\n",
        "\n",
        "#dataset_ED_test = tio.SubjectsDataset(subjects_ED)\n",
        "#dataset_ES_test = tio.SubjectsDataset(subjects_ES)\n",
        "\n",
        "\n",
        "dataset_ED_test = tio.SubjectsDataset(subjects_ED, transform=validation_transform)\n",
        "dataset_ES_test = tio.SubjectsDataset(subjects_ES, transform=validation_transform)\n",
        "\n",
        "\n",
        "print('Dataset size:', len(dataset_ED_test), 'subjects')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-8Tamfv4VOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc0e9ae1-0762-4427-a9e1-012ad0fb40ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 100 subjects\n"
          ]
        }
      ],
      "source": [
        "# create a dataset of first type of mri and the second one\n",
        "\n",
        "subjects_ED = []\n",
        "subjects_ES = []\n",
        "subjects_ED_rot = []\n",
        "subjects_ES_rot = []\n",
        "\n",
        "permute = np.random.permutation(100)+1\n",
        "\n",
        "\n",
        "for i in permute:\n",
        "  current_dir = os.path.join(data_path, 'Train', counter(i))\n",
        "  subject_ED = tio.Subject(\n",
        "        mri=tio.ScalarImage(os.path.join(current_dir, counter(i)+'_ED.nii')),\n",
        "        segment=tio.LabelMap(os.path.join(current_dir, counter(i)+'_ED_seg.nii')),\n",
        "        height=df_meta_train.iloc[i-1]['Height'],\n",
        "        weight=df_meta_train.iloc[i-1]['Weight'],\n",
        "        category=df_meta_train.iloc[i-1]['Category']\n",
        "\n",
        "    )\n",
        "\n",
        "  subject_ES = tio.Subject(\n",
        "        mri=tio.ScalarImage(os.path.join(current_dir, counter(i)+'_ES.nii')),\n",
        "        segment=tio.LabelMap(os.path.join(current_dir, counter(i)+'_ES_seg.nii')),\n",
        "        height=df_meta_train.iloc[i-1]['Height'],\n",
        "        weight=df_meta_train.iloc[i-1]['Weight'],\n",
        "        category=df_meta_train.iloc[i-1]['Category']\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "  subjects_ED.append(subject_ED)\n",
        "  subjects_ES.append(subject_ES)\n",
        "\n",
        "\n",
        "\n",
        "#dataset_ED_train = tio.SubjectsDataset(subjects_ED)\n",
        "\n",
        "#dataset_ES_train = tio.SubjectsDataset(subjects_ES)\n",
        "\n",
        "\n",
        "\n",
        "dataset_ED_train = tio.SubjectsDataset(subjects_ED, transform=training_transform)\n",
        "#dataset_ED_train_rot_ = tio.SubjectsDataset(subjects_ED, transform=training_transform_rot)\n",
        "#dataset_ED_train = ConcatDataset([dataset_ED_train_, dataset_ED_train_rot_])\n",
        "\n",
        "\n",
        "\n",
        "dataset_ES_train = tio.SubjectsDataset(subjects_ES, transform=training_transform)\n",
        "#dataset_ES_train_rot_ = tio.SubjectsDataset(subjects_ES, transform=training_transform_rot)\n",
        "#dataset_ES_train = ConcatDataset([dataset_ES_train_, dataset_ES_train_rot_])\n",
        "\n",
        "'''\n",
        "lengths = [int(len(dataset_ED_train)*0.8), int(len(dataset_ED_train)*0.2)]\n",
        "train_ED, valid_ED = torch.utils.data.random_split(dataset_ED_train, lengths)\n",
        "lengths = [int(len(dataset_ES_train)*0.8), int(len(dataset_ES_train)*0.2)]\n",
        "train_ES, valid_ES = torch.utils.data.random_split(dataset_ES_train, lengths)\n",
        "'''\n",
        "print('Dataset size:', len(dataset_ED_train), 'subjects')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLK5Otw84nW5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "training_batch_size = 3\n",
        "validation_batch_size = 2 * training_batch_size\n",
        "'''\n",
        "\n",
        "training_batch_size = 1\n",
        "validation_batch_size = 1\n",
        "\n",
        "\n",
        "\n",
        "training_loader_ED = torch.utils.data.DataLoader(\n",
        "    dataset_ED_train,\n",
        "    batch_size=training_batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "training_loader_ES = torch.utils.data.DataLoader(\n",
        "    dataset_ES_train,\n",
        "    batch_size=training_batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        ")\n",
        "\n",
        "\n",
        "test_ED_loader = torch.utils.data.DataLoader(\n",
        "    dataset_ED_test,\n",
        "    batch_size=validation_batch_size,\n",
        "    num_workers=num_workers)\n",
        "\n",
        "test_ES_loader = torch.utils.data.DataLoader(\n",
        "    dataset_ES_test,\n",
        "    batch_size=validation_batch_size,\n",
        "    num_workers=num_workers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# calcutaing approximate thickness, circumeference, and circularity"
      ],
      "metadata": {
        "id": "LVwiml38z8aX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TG_v-Acbszm"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def circularity(perimeter, area):\n",
        "  radius = perimeter / (2 * math.pi)\n",
        "  circular_area = math.pi * radius ** 2\n",
        "  return circular_area / area"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrxGUYHOue08"
      },
      "outputs": [],
      "source": [
        "# extracting some features from the train set\n",
        "num_points = 30\n",
        "angles = np.linspace(0, 2*np.pi, num_points)\n",
        "\n",
        "ED_max_thickness_MYO = []\n",
        "ED_min_thickness_MYO = []\n",
        "ED_std_thickness_MYO = []\n",
        "ED_mean_thickness_MYO = []\n",
        "ED_circular_MYO = []\n",
        "ED_circumference_MYO = []\n",
        "\n",
        "ES_max_thickness_MYO = []\n",
        "ES_min_thickness_MYO = []\n",
        "ES_std_thickness_MYO = []\n",
        "ES_mean_thickness_MYO = []\n",
        "ES_circular_MYO = []\n",
        "ES_circumference_MYO = []\n",
        "\n",
        "\n",
        "\n",
        "for i, (input_1, input_2) in enumerate(zip(training_loader_ED, training_loader_ES)):\n",
        "\n",
        "  MYO_ED = (input_1['segment'][tio.DATA]==2).int()[0][0].cpu().numpy()\n",
        "  MYO_ES = (input_2['segment'][tio.DATA]==2).int()[0][0].cpu().numpy()\n",
        "\n",
        "  LV_ED = (input_1['segment'][tio.DATA]==3).int()[0][0].cpu().numpy()\n",
        "  LV_ES = (input_2['segment'][tio.DATA]==3).int()[0][0].cpu().numpy()\n",
        "\n",
        "\n",
        "  for j in range(MYO_ED.shape[2]):\n",
        "    current_layer_ED = MYO_ED[:,:,j]\n",
        "    current_layer_ES = MYO_ES[:,:,j]\n",
        "\n",
        "    current_layer_LV_ED = LV_ED[:,:,j]\n",
        "    current_layer_LV_ES = LV_ES[:,:,j]\n",
        "\n",
        "    # for each layer we compute the area that will later be used in calculating the circularity\n",
        "    area_ED = np.sum(current_layer_ED)+np.sum(current_layer_LV_ED)\n",
        "    area_ES = np.sum(current_layer_ES)+np.sum(current_layer_LV_ES)\n",
        "\n",
        "    # this will mater be divided by the mean thickness of the Myo, to caluclate an approximation of the perimeter\n",
        "    thick_perim_ED = np.sum(current_layer_ED)\n",
        "    thick_perim_ES = np.sum(current_layer_ES)\n",
        "\n",
        "    ring_indices_ED = np.argwhere(current_layer_ED)\n",
        "    ring_indices_ES = np.argwhere(current_layer_ES)\n",
        "\n",
        "    if len(ring_indices_ED)>0:\n",
        "\n",
        "      center_ED = np.mean(ring_indices_ED, axis=0)\n",
        "      distances_ED = np.linalg.norm(ring_indices_ED - center_ED, axis=1)\n",
        "      min_radius = np.min(distances_ED)\n",
        "      # print(min_radius)\n",
        "\n",
        "      current_cut_thicknesses = []\n",
        "\n",
        "      for angle in angles:\n",
        "        unit_vector = np.array([np.cos(angle), np.sin(angle)])\n",
        "        point_on_ring = center_ED + min_radius * unit_vector\n",
        "        point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "        augmenter = 0\n",
        "        while point_on_ring_int[0] >=0 and point_on_ring_int[1]>=0 and point_on_ring_int[0] < current_layer_ED.shape[0] and point_on_ring_int[1] < current_layer_ED.shape[1] and  current_layer_ED[point_on_ring_int[0],point_on_ring_int[1]]==0:\n",
        "          augmenter += 0.05\n",
        "          point_on_ring = center_ED + (min_radius+augmenter) * unit_vector\n",
        "          point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "\n",
        "        start_ring_current_dir = np.linalg.norm(point_on_ring_int - center_ED)\n",
        "\n",
        "\n",
        "        point_on_ring = center_ED + (min_radius+augmenter) * unit_vector\n",
        "        point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "        while point_on_ring_int[0] >=0 and point_on_ring_int[1]>=0 and point_on_ring_int[0] < current_layer_ED.shape[0] and point_on_ring_int[1] < current_layer_ED.shape[1] and  current_layer_ED[point_on_ring_int[0],point_on_ring_int[1]]==1:\n",
        "          augmenter += 0.05\n",
        "          point_on_ring = center_ED + (min_radius+augmenter) * unit_vector\n",
        "          point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "\n",
        "        end_ring_current_dir = np.linalg.norm(point_on_ring_int - center_ED)\n",
        "\n",
        "        # print(start_ring_current_dir, '  ', end_ring_current_dir)\n",
        "\n",
        "\n",
        "        thickness_current_angle = end_ring_current_dir - start_ring_current_dir\n",
        "        current_cut_thicknesses.append(thickness_current_angle)\n",
        "\n",
        "    else:\n",
        "      current_cut_thicknesses = np.zeros_like(angles)\n",
        "\n",
        "\n",
        "    # for the current layer j\n",
        "    mean_thickness_layer = np.mean(current_cut_thicknesses)\n",
        "    # this is of shape 10. We can use this to calculate circularity for each layer =>\n",
        "    # take all of those == 2 in each layer, divide by mean thickness, and this gives an approximation of the perimeter\n",
        "    # then we neeed to calculate the area of the shape => sum of ==3 and ==2 for each layer.\n",
        "    # we can then use the circularity function defined above to calculate the cirularity.\n",
        "    if mean_thickness_layer!=0:\n",
        "      approx_perim_ED = thick_perim_ED/mean_thickness_layer\n",
        "      circular_ED = circularity(approx_perim_ED, area_ED)\n",
        "    else:\n",
        "      approx_perim_ED = -1\n",
        "      circular_ED = -1\n",
        "\n",
        "    std_thickness_layer = np.std(current_cut_thicknesses)\n",
        "    min_thickness_layer = np.min(current_cut_thicknesses)\n",
        "    max_thickness_layer = np.max(current_cut_thicknesses)\n",
        "\n",
        "\n",
        "    # adding it up for the current layer, and there are 10 layers for each image\n",
        "    ED_max_thickness_MYO.append(max_thickness_layer)\n",
        "    ED_min_thickness_MYO .append(min_thickness_layer)\n",
        "    ED_std_thickness_MYO.append(std_thickness_layer)\n",
        "    ED_mean_thickness_MYO.append(mean_thickness_layer)\n",
        "    ED_circular_MYO.append(circular_ED)\n",
        "    ED_circumference_MYO.append(approx_perim_ED)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if len(ring_indices_ES)>0:\n",
        "\n",
        "      center_ES = np.mean(ring_indices_ES, axis=0)\n",
        "      distances_ES = np.linalg.norm(ring_indices_ES - center_ES, axis=1)\n",
        "      min_radius = np.min(distances_ES)\n",
        "      # print(min_radius)\n",
        "\n",
        "      current_cut_thicknesses = []\n",
        "\n",
        "      for angle in angles:\n",
        "        unit_vector = np.array([np.cos(angle), np.sin(angle)])\n",
        "        point_on_ring = center_ES + min_radius * unit_vector\n",
        "        point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "        augmenter = 0\n",
        "        while point_on_ring_int[0] >=0 and point_on_ring_int[1]>=0 and point_on_ring_int[0] < current_layer_ES.shape[0] and point_on_ring_int[1] < current_layer_ES.shape[1] and  current_layer_ES[point_on_ring_int[0],point_on_ring_int[1]]==0:\n",
        "          augmenter += 0.05\n",
        "          point_on_ring = center_ES + (min_radius+augmenter) * unit_vector\n",
        "          point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "\n",
        "        start_ring_current_dir = np.linalg.norm(point_on_ring_int - center_ES)\n",
        "\n",
        "\n",
        "        point_on_ring = center_ES + (min_radius+augmenter) * unit_vector\n",
        "        point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "        while point_on_ring_int[0] >=0 and point_on_ring_int[1]>=0 and point_on_ring_int[0] < current_layer_ES.shape[0] and point_on_ring_int[1] < current_layer_ES.shape[1] and  current_layer_ES[point_on_ring_int[0],point_on_ring_int[1]]==1:\n",
        "          augmenter += 0.05\n",
        "          point_on_ring = center_ES + (min_radius+augmenter) * unit_vector\n",
        "          point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "\n",
        "        end_ring_current_dir = np.linalg.norm(point_on_ring_int - center_ES)\n",
        "\n",
        "        # print(start_ring_current_dir, '  ', end_ring_current_dir)\n",
        "\n",
        "\n",
        "        thickness_current_angle = end_ring_current_dir - start_ring_current_dir\n",
        "        current_cut_thicknesses.append(thickness_current_angle)\n",
        "\n",
        "    else:\n",
        "      current_cut_thicknesses = np.zeros_like(angles)\n",
        "\n",
        "\n",
        "    # for the current layer j\n",
        "    mean_thickness_layer = np.mean(current_cut_thicknesses)\n",
        "    if mean_thickness_layer!=0:\n",
        "      approx_perim_ES = thick_perim_ES/mean_thickness_layer\n",
        "      circular_ES = circularity(approx_perim_ES, area_ES)\n",
        "    else:\n",
        "      approx_perim_ES = -1\n",
        "      circular_ES = -1\n",
        "    std_thickness_layer = np.std(current_cut_thicknesses)\n",
        "    min_thickness_layer = np.min(current_cut_thicknesses)\n",
        "    max_thickness_layer = np.max(current_cut_thicknesses)\n",
        "\n",
        "\n",
        "    # adding it up for the current layer, and there are 10 layers for each image\n",
        "    ES_max_thickness_MYO.append(max_thickness_layer)\n",
        "    ES_min_thickness_MYO .append(min_thickness_layer)\n",
        "    ES_std_thickness_MYO.append(std_thickness_layer)\n",
        "    ES_mean_thickness_MYO.append(mean_thickness_layer)\n",
        "    ES_circular_MYO.append(circular_ES)\n",
        "    ES_circumference_MYO.append(approx_perim_ES)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PP3I_pStTghT"
      },
      "outputs": [],
      "source": [
        "train_ED_max_thickness_MYO = np.array(ED_max_thickness_MYO).reshape(-1,10)\n",
        "train_ED_min_thickness_MYO = np.array(ED_min_thickness_MYO).reshape(-1,10)\n",
        "train_ED_std_thickness_MYO = np.array(ED_std_thickness_MYO).reshape(-1,10)\n",
        "train_ED_mean_thickness_MYO = np.array(ED_mean_thickness_MYO).reshape(-1,10)\n",
        "train_ED_circular_MYO = np.array(ED_circular_MYO).reshape(-1,10)\n",
        "train_ED_circumference_MYO = np.array(ED_circumference_MYO).reshape(-1,10)\n",
        "\n",
        "train_ES_max_thickness_MYO = np.array(ES_max_thickness_MYO).reshape(-1,10)\n",
        "train_ES_min_thickness_MYO = np.array(ES_min_thickness_MYO).reshape(-1,10)\n",
        "train_ES_std_thickness_MYO = np.array(ES_std_thickness_MYO).reshape(-1,10)\n",
        "train_ES_mean_thickness_MYO = np.array(ES_mean_thickness_MYO).reshape(-1,10)\n",
        "train_ES_circular_MYO = np.array(ES_circular_MYO).reshape(-1,10)\n",
        "train_ES_circumference_MYO = np.array(ES_circumference_MYO).reshape(-1,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd28kF3t4xvZ"
      },
      "outputs": [],
      "source": [
        "# doing the calculation for the train set\n",
        "# we have the volumes already\n",
        "\n",
        "\n",
        "volume_ED_LV = []\n",
        "volume_ED_RV = []\n",
        "volume_ED_MYO = []\n",
        "\n",
        "volume_ES_LV = []\n",
        "volume_ES_RV = []\n",
        "volume_ES_MYO = []\n",
        "\n",
        "Vol_Change_LV = []\n",
        "Vol_Change_RV = []\n",
        "Vol_Change_MYO = []\n",
        "\n",
        "\n",
        "LV_ejection = []\n",
        "RV_ejection = []\n",
        "\n",
        "rat_RV_LV_ED = []\n",
        "rat_RV_LV_ES = []\n",
        "\n",
        "rat_MYO_LV_ED = []\n",
        "rat_MYO_LV_ES = []\n",
        "\n",
        "height = []\n",
        "weight = []\n",
        "\n",
        "\n",
        "target = []\n",
        "\n",
        "for i, (input_1, input_2) in enumerate(zip(training_loader_ED, training_loader_ES)):\n",
        "  LV_ED = torch.sum((input_1['segment'][tio.DATA]==3).int(), (1,2,3,4)).float()\n",
        "  RV_ED = torch.sum((input_1['segment'][tio.DATA]==1).int(), (1,2,3,4)).float()\n",
        "  MYO_ED = torch.sum((input_1['segment'][tio.DATA]==2).int(), (1,2,3,4)).float()\n",
        "\n",
        "  vol_total = LV_ED+RV_ED+MYO_ED\n",
        "  LV_ED = LV_ED/vol_total\n",
        "  RV_ED = RV_ED/vol_total\n",
        "  MYO_ED = MYO_ED/vol_total\n",
        "\n",
        "  volume_ED_LV.append(LV_ED)\n",
        "  volume_ED_RV.append(RV_ED)\n",
        "  volume_ED_MYO.append(MYO_ED)\n",
        "\n",
        "\n",
        "  rat_RV_LV_ED.append(RV_ED/LV_ED)\n",
        "  rat_MYO_LV_ED.append(MYO_ED/LV_ED)\n",
        "\n",
        "\n",
        "  LV_ES = torch.sum((input_2['segment'][tio.DATA]==3).int(), (1,2,3,4)).float()\n",
        "  RV_ES = torch.sum((input_2['segment'][tio.DATA]==1).int(), (1,2,3,4)).float()\n",
        "  MYO_ES = torch.sum((input_2['segment'][tio.DATA]==2).int(), (1,2,3,4)).float()\n",
        "  vol_total = LV_ES+RV_ES+MYO_ES\n",
        "  LV_ES = LV_ES/vol_total\n",
        "  RV_ES = RV_ES/vol_total\n",
        "  MYO_ES = MYO_ES/vol_total\n",
        "\n",
        "  volume_ES_LV.append(LV_ES)\n",
        "  volume_ES_RV.append(RV_ES)\n",
        "  volume_ES_MYO.append(MYO_ES)\n",
        "\n",
        "  rat_RV_LV_ES.append(RV_ES/LV_ES)\n",
        "  rat_MYO_LV_ES.append(MYO_ES/LV_ES)\n",
        "\n",
        "\n",
        "  LV_ejection.append((LV_ES-LV_ED)/LV_ED)\n",
        "  RV_ejection.append((RV_ES-RV_ED)/RV_ED)\n",
        "\n",
        "  Vol_Change_LV.append((LV_ES-LV_ED))\n",
        "  Vol_Change_RV.append((RV_ES-RV_ED))\n",
        "\n",
        "\n",
        "  height.append(input_1['height'])\n",
        "  weight.append(input_1['weight'])\n",
        "\n",
        "\n",
        "\n",
        "  target.append(input_1['category'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDq8x2ZP6YVk"
      },
      "outputs": [],
      "source": [
        "volume_ED_LV = np.concatenate(volume_ED_LV)[:, None]\n",
        "volume_ED_RV = np.concatenate(volume_ED_RV)[:, None]\n",
        "volume_ED_MYO = np.concatenate(volume_ED_MYO)[:, None]\n",
        "\n",
        "volume_ES_LV = np.concatenate(volume_ES_LV)[:, None]\n",
        "volume_ES_RV = np.concatenate(volume_ES_RV)[:, None]\n",
        "volume_ES_MYO = np.concatenate(volume_ES_MYO)[:, None]\n",
        "\n",
        "\n",
        "LV_ejection = np.concatenate(LV_ejection)[:, None]\n",
        "RV_ejection = np.concatenate(RV_ejection)[:, None]\n",
        "\n",
        "\n",
        "Vol_Change_LV = np.concatenate(Vol_Change_LV)[:, None]\n",
        "Vol_Change_RV = np.concatenate(Vol_Change_RV)[:, None]\n",
        "\n",
        "\n",
        "rat_RV_LV_ED = np.concatenate(rat_RV_LV_ED)[:, None]\n",
        "rat_RV_LV_ES = np.concatenate(rat_RV_LV_ES)[:, None]\n",
        "\n",
        "rat_MYO_LV_ED = np.concatenate(rat_MYO_LV_ED)[:, None]\n",
        "rat_MYO_LV_ES = np.concatenate(rat_MYO_LV_ES)[:, None]\n",
        "\n",
        "height = np.concatenate(height)[:, None]\n",
        "weight = np.concatenate(weight)[:, None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgUWdIqS9g-G"
      },
      "outputs": [],
      "source": [
        "X_train = np.concatenate((volume_ED_LV,volume_ED_RV,volume_ED_MYO,\n",
        "                          volume_ES_LV,volume_ES_RV,volume_ES_MYO,\n",
        "                          LV_ejection,RV_ejection,\n",
        "                          Vol_Change_LV,Vol_Change_RV,\n",
        "                          rat_RV_LV_ED,rat_RV_LV_ES,\n",
        "                          rat_MYO_LV_ED,rat_MYO_LV_ES,\n",
        "                          train_ED_mean_thickness_MYO, train_ES_mean_thickness_MYO,\n",
        "                          train_ED_std_thickness_MYO, train_ES_std_thickness_MYO,\n",
        "                          train_ED_min_thickness_MYO, train_ES_min_thickness_MYO,\n",
        "                          train_ED_max_thickness_MYO, train_ES_max_thickness_MYO,\n",
        "                          train_ED_circular_MYO, train_ES_circular_MYO,\n",
        "                          train_ED_circumference_MYO, train_ES_circumference_MYO,\n",
        "                          height,weight), axis=1)\n",
        "y_train = np.concatenate(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBYtW2O7r3rg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636765e5-2cb1-4a90-b32e-3b09a8da4814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 136)\n",
            "(100,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg0J6QyQnZ5E"
      },
      "source": [
        "# Operations on test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding the left ventricle regions in test dataset, ED"
      ],
      "metadata": {
        "id": "wEroihY6eHmr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AOE2h50-QLl"
      },
      "outputs": [],
      "source": [
        "test_masks_ED = []\n",
        "for i, input in enumerate(test_ED_loader):\n",
        "\n",
        "  target = (input['segment'][tio.DATA]).to(device).int().cpu().numpy()\n",
        "  # first of all, put everything to the class 0 and 2 => let the zero be zero, let the 2 be 2, convert 1 to 0\n",
        "  target[target==1] = 0\n",
        "\n",
        "\n",
        "  for j in range(target.shape[0]):\n",
        "    current_batch_target = target[j,0,:]-1 # so the values will be -1 and 1\n",
        "    #print(current_batch_target.shape)\n",
        "    mask_LV = np.zeros_like(current_batch_target)\n",
        "\n",
        "    for n_slice in range(current_batch_target.shape[2]):\n",
        "      for x_step in range(current_batch_target.shape[0]):\n",
        "\n",
        "        y_step = 0\n",
        "        start_LV = -1\n",
        "        end_LV = -1\n",
        "        while y_step < current_batch_target.shape[1] and current_batch_target[x_step,y_step,n_slice]==-1:\n",
        "          y_step += 1\n",
        "        while y_step < current_batch_target.shape[1] and current_batch_target[x_step,y_step,n_slice]==1:\n",
        "          y_step += 1\n",
        "        start_LV = y_step\n",
        "        while y_step < current_batch_target.shape[1] and current_batch_target[x_step,y_step,n_slice]==-1:\n",
        "          y_step += 1\n",
        "        end_LV = y_step\n",
        "        if start_LV != current_batch_target.shape[1] and end_LV != current_batch_target.shape[1]:\n",
        "          for k in range(start_LV, end_LV):\n",
        "            mask_LV[x_step, k, n_slice] = 1\n",
        "\n",
        "  test_masks_ED.append(mask_LV)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding the left ventricle regions in test dataset, ES"
      ],
      "metadata": {
        "id": "GoRIQYTiePgr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSWvv8zGDMtE"
      },
      "outputs": [],
      "source": [
        "test_masks_ES = []\n",
        "for i, input in enumerate(test_ES_loader):\n",
        "\n",
        "  target = (input['segment'][tio.DATA]).to(device).int().cpu().numpy()\n",
        "  # first of all, put everything to the class 0 and 2 => let the zero be zero, let the 2 be 2, convert 1 to 0\n",
        "  target[target==1] = 0\n",
        "\n",
        "\n",
        "  for j in range(target.shape[0]):\n",
        "    current_batch_target = target[j,0,:]-1 # so the values will be -1 and 1\n",
        "    #print(current_batch_target.shape)\n",
        "    mask_LV = np.zeros_like(current_batch_target)\n",
        "\n",
        "    for n_slice in range(current_batch_target.shape[2]):\n",
        "      for x_step in range(current_batch_target.shape[0]):\n",
        "\n",
        "        y_step = 0\n",
        "        start_LV = -1\n",
        "        end_LV = -1\n",
        "        while y_step < current_batch_target.shape[1] and current_batch_target[x_step,y_step,n_slice]==-1:\n",
        "          y_step += 1\n",
        "        while y_step < current_batch_target.shape[1] and current_batch_target[x_step,y_step,n_slice]==1:\n",
        "          y_step += 1\n",
        "        start_LV = y_step\n",
        "        while y_step < current_batch_target.shape[1] and current_batch_target[x_step,y_step,n_slice]==-1:\n",
        "          y_step += 1\n",
        "        end_LV = y_step\n",
        "        if start_LV != current_batch_target.shape[1] and end_LV != current_batch_target.shape[1]:\n",
        "          for k in range(start_LV, end_LV):\n",
        "            mask_LV[x_step, k, n_slice] = 1\n",
        "\n",
        "  test_masks_ES.append(mask_LV)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Having a look at some of the segmented images"
      ],
      "metadata": {
        "id": "A8D-b_c9epaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 5,\n",
        "                        figsize =(10, 7),\n",
        "                        tight_layout = True)\n",
        "\n",
        "for i, input in enumerate(test_ES_loader):\n",
        "\n",
        "  if i%10==0:\n",
        "    target = (input['segment'][tio.DATA]).to(device).int().cpu().numpy()\n",
        "    axs[0,i//10].imshow(test_masks_ES[i][:,:,3])\n",
        "    axs[1,i//10].imshow(target[0,0,:,:,3])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "m-dKp11ieo1g",
        "outputId": "0e8b55f1-9c4e-49e8-a6aa-e9b945d3199a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B33HxuDUiEZ"
      },
      "outputs": [],
      "source": [
        "# extracting some features from the test set\n",
        "num_points = 30\n",
        "angles = np.linspace(0, 2*np.pi, num_points)\n",
        "\n",
        "ED_max_thickness_MYO = []\n",
        "ED_min_thickness_MYO = []\n",
        "ED_std_thickness_MYO = []\n",
        "ED_mean_thickness_MYO = []\n",
        "ED_circular_MYO = []\n",
        "ED_circumference_MYO = []\n",
        "\n",
        "ES_max_thickness_MYO = []\n",
        "ES_min_thickness_MYO = []\n",
        "ES_std_thickness_MYO = []\n",
        "ES_mean_thickness_MYO = []\n",
        "ES_circular_MYO = []\n",
        "ES_circumference_MYO = []\n",
        "\n",
        "\n",
        "for i, (input_1, input_2) in enumerate(zip(test_ED_loader, test_ES_loader)):\n",
        "\n",
        "  MYO_ED = (input_1['segment'][tio.DATA]==2).int()[0][0].cpu().numpy()\n",
        "  MYO_ES = (input_2['segment'][tio.DATA]==2).int()[0][0].cpu().numpy()\n",
        "\n",
        "  LV_ED = test_masks_ED[i]\n",
        "  LV_ES = test_masks_ES[i]\n",
        "\n",
        "\n",
        "  for j in range(MYO_ED.shape[2]):\n",
        "    current_layer_ED = MYO_ED[:,:,j]\n",
        "    current_layer_ES = MYO_ES[:,:,j]\n",
        "\n",
        "    current_layer_LV_ED = LV_ED[:,:,j]\n",
        "    current_layer_LV_ES = LV_ES[:,:,j]\n",
        "\n",
        "    # for each layer we compute the area that will later be used in calculating the circularity\n",
        "    area_ED = np.sum(current_layer_ED)+np.sum(current_layer_LV_ED)\n",
        "    area_ES = np.sum(current_layer_ES)+np.sum(current_layer_LV_ES)\n",
        "\n",
        "    # this will mater be divided by the mean thickness of the Myo, to caluclate an approximation of the perimeter\n",
        "    thick_perim_ED = np.sum(current_layer_ED)\n",
        "    thick_perim_ES = np.sum(current_layer_ES)\n",
        "\n",
        "    ring_indices_ED = np.argwhere(current_layer_ED)\n",
        "    ring_indices_ES = np.argwhere(current_layer_ES)\n",
        "\n",
        "    if len(ring_indices_ED)>0:\n",
        "\n",
        "      center_ED = np.mean(ring_indices_ED, axis=0)\n",
        "      distances_ED = np.linalg.norm(ring_indices_ED - center_ED, axis=1)\n",
        "      min_radius = np.min(distances_ED)\n",
        "      # print(min_radius)\n",
        "\n",
        "      current_cut_thicknesses = []\n",
        "\n",
        "      for angle in angles:\n",
        "        unit_vector = np.array([np.cos(angle), np.sin(angle)])\n",
        "        point_on_ring = center_ED + min_radius * unit_vector\n",
        "        point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "        augmenter = 0\n",
        "        while point_on_ring_int[0] >=0 and point_on_ring_int[1]>=0 and point_on_ring_int[0] < current_layer_ED.shape[0] and point_on_ring_int[1] < current_layer_ED.shape[1] and current_layer_ED[point_on_ring_int[0],point_on_ring_int[1]]==0:\n",
        "          augmenter += 0.05\n",
        "          point_on_ring = center_ED + (min_radius+augmenter) * unit_vector\n",
        "          point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "\n",
        "        start_ring_current_dir = np.linalg.norm(point_on_ring_int - center_ED)\n",
        "\n",
        "\n",
        "        point_on_ring = center_ED + (min_radius+augmenter) * unit_vector\n",
        "        point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "        while  point_on_ring_int[0] >=0 and point_on_ring_int[1]>=0 and point_on_ring_int[0] < current_layer_ED.shape[0] and point_on_ring_int[1] < current_layer_ED.shape[1] and current_layer_ED[point_on_ring_int[0],point_on_ring_int[1]]==1:\n",
        "          augmenter += 0.05\n",
        "          point_on_ring = center_ED + (min_radius+augmenter) * unit_vector\n",
        "          point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "\n",
        "        end_ring_current_dir = np.linalg.norm(point_on_ring_int - center_ED)\n",
        "\n",
        "        # print(start_ring_current_dir, '  ', end_ring_current_dir)\n",
        "\n",
        "\n",
        "        thickness_current_angle = end_ring_current_dir - start_ring_current_dir\n",
        "        current_cut_thicknesses.append(thickness_current_angle)\n",
        "\n",
        "    else:\n",
        "      current_cut_thicknesses = np.zeros_like(angles)\n",
        "\n",
        "\n",
        "    # for the current layer j\n",
        "    mean_thickness_layer = np.mean(current_cut_thicknesses)\n",
        "    if mean_thickness_layer!=0:\n",
        "      approx_perim_ED = thick_perim_ED/mean_thickness_layer\n",
        "      circular_ED = circularity(approx_perim_ED, area_ED)\n",
        "    else:\n",
        "      approx_perim_ED = -1\n",
        "      circular_ED = -1\n",
        "    std_thickness_layer = np.std(current_cut_thicknesses)\n",
        "    min_thickness_layer = np.min(current_cut_thicknesses)\n",
        "    max_thickness_layer = np.max(current_cut_thicknesses)\n",
        "\n",
        "\n",
        "    # adding it up for the current layer, and there are 10 layers for each image\n",
        "    ED_max_thickness_MYO.append(max_thickness_layer)\n",
        "    ED_min_thickness_MYO .append(min_thickness_layer)\n",
        "    ED_std_thickness_MYO.append(std_thickness_layer)\n",
        "    ED_mean_thickness_MYO.append(mean_thickness_layer)\n",
        "    ED_circular_MYO.append(circular_ED)\n",
        "    ED_circumference_MYO.append(approx_perim_ED)\n",
        "\n",
        "\n",
        "    if len(ring_indices_ES)>0:\n",
        "\n",
        "      center_ES = np.mean(ring_indices_ES, axis=0)\n",
        "      distances_ES = np.linalg.norm(ring_indices_ES - center_ES, axis=1)\n",
        "      min_radius = np.min(distances_ES)\n",
        "      # print(min_radius)\n",
        "\n",
        "      current_cut_thicknesses = []\n",
        "\n",
        "      for angle in angles:\n",
        "        unit_vector = np.array([np.cos(angle), np.sin(angle)])\n",
        "        point_on_ring = center_ES + min_radius * unit_vector\n",
        "        point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "        augmenter = 0\n",
        "        while  point_on_ring_int[0] >=0 and point_on_ring_int[1]>=0 and point_on_ring_int[0] < current_layer_ED.shape[0] and point_on_ring_int[1] < current_layer_ED.shape[1] and current_layer_ES[point_on_ring_int[0],point_on_ring_int[1]]==0:\n",
        "          augmenter += 0.05\n",
        "          point_on_ring = center_ES + (min_radius+augmenter) * unit_vector\n",
        "          point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "\n",
        "        start_ring_current_dir = np.linalg.norm(point_on_ring_int - center_ES)\n",
        "\n",
        "\n",
        "        point_on_ring = center_ES + (min_radius+augmenter) * unit_vector\n",
        "        point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "        while point_on_ring_int[0] >=0 and point_on_ring_int[1]>=0 and point_on_ring_int[0] < current_layer_ED.shape[0] and point_on_ring_int[1] < current_layer_ED.shape[1] and current_layer_ES[point_on_ring_int[0],point_on_ring_int[1]]==1:\n",
        "          augmenter += 0.05\n",
        "          point_on_ring = center_ES + (min_radius+augmenter) * unit_vector\n",
        "          point_on_ring_int = point_on_ring.astype(np.int64)\n",
        "\n",
        "        end_ring_current_dir = np.linalg.norm(point_on_ring_int - center_ES)\n",
        "\n",
        "        # print(start_ring_current_dir, '  ', end_ring_current_dir)\n",
        "\n",
        "\n",
        "        thickness_current_angle = end_ring_current_dir - start_ring_current_dir\n",
        "        current_cut_thicknesses.append(thickness_current_angle)\n",
        "\n",
        "    else:\n",
        "      current_cut_thicknesses = np.zeros_like(angles)\n",
        "\n",
        "\n",
        "    # for the current layer j\n",
        "    mean_thickness_layer = np.mean(current_cut_thicknesses)\n",
        "    if mean_thickness_layer!=0:\n",
        "      approx_perim_ES = thick_perim_ES/mean_thickness_layer\n",
        "      circular_ES = circularity(approx_perim_ES, area_ES)\n",
        "    else:\n",
        "      approx_perim_ES = -1\n",
        "      circular_ES = -1\n",
        "    std_thickness_layer = np.std(current_cut_thicknesses)\n",
        "    min_thickness_layer = np.min(current_cut_thicknesses)\n",
        "    max_thickness_layer = np.max(current_cut_thicknesses)\n",
        "\n",
        "\n",
        "    # adding it up for the current layer, and there are 10 layers for each image\n",
        "    ES_max_thickness_MYO.append(max_thickness_layer)\n",
        "    ES_min_thickness_MYO .append(min_thickness_layer)\n",
        "    ES_std_thickness_MYO.append(std_thickness_layer)\n",
        "    ES_mean_thickness_MYO.append(mean_thickness_layer)\n",
        "    ES_circular_MYO.append(circular_ES)\n",
        "    ES_circumference_MYO.append(approx_perim_ES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CG3yhupHUvZ4"
      },
      "outputs": [],
      "source": [
        "test_ED_max_thickness_MYO = np.array(ED_max_thickness_MYO).reshape(-1,10)\n",
        "test_ED_min_thickness_MYO = np.array(ED_min_thickness_MYO).reshape(-1,10)\n",
        "test_ED_std_thickness_MYO = np.array(ED_std_thickness_MYO).reshape(-1,10)\n",
        "test_ED_mean_thickness_MYO = np.array(ED_mean_thickness_MYO).reshape(-1,10)\n",
        "test_ED_circular_MYO = np.array(ED_circular_MYO).reshape(-1,10)\n",
        "test_ED_circumference_MYO = np.array(ED_circumference_MYO).reshape(-1,10)\n",
        "\n",
        "test_ES_max_thickness_MYO = np.array(ES_max_thickness_MYO).reshape(-1,10)\n",
        "test_ES_min_thickness_MYO = np.array(ES_min_thickness_MYO).reshape(-1,10)\n",
        "test_ES_std_thickness_MYO = np.array(ES_std_thickness_MYO).reshape(-1,10)\n",
        "test_ES_mean_thickness_MYO = np.array(ES_mean_thickness_MYO).reshape(-1,10)\n",
        "test_ES_circular_MYO = np.array(ES_circular_MYO).reshape(-1,10)\n",
        "test_ES_circumference_MYO = np.array(ES_circumference_MYO).reshape(-1,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJFeClKe9s1m"
      },
      "outputs": [],
      "source": [
        "volume_ED_LV_test = []\n",
        "volume_ED_RV_test = []\n",
        "volume_ED_MYO_test = []\n",
        "\n",
        "\n",
        "\n",
        "volume_ES_LV_test = []\n",
        "volume_ES_RV_test = []\n",
        "volume_ES_MYO_test = []\n",
        "\n",
        "\n",
        "LV_ejection_test = []\n",
        "RV_ejection_test = []\n",
        "\n",
        "Vol_Change_LV_test = []\n",
        "Vol_Change_RV_test = []\n",
        "Vol_Change_MYO_test = []\n",
        "\n",
        "rat_RV_LV_ED_test = []\n",
        "rat_RV_LV_ES_test = []\n",
        "\n",
        "rat_MYO_LV_ED_test = []\n",
        "rat_MYO_LV_ES_test = []\n",
        "\n",
        "height_test = []\n",
        "weight_test = []\n",
        "\n",
        "\n",
        "\n",
        "for i, (input_1, input_2) in enumerate(zip(test_ED_loader, test_ES_loader)):\n",
        "  # LV_ED = torch.sum((input_1['segment'][tio.DATA]==3).int(), (1,2,3,4)).float()\n",
        "  LV_ED = np.sum(test_masks_ED[i])\n",
        "  RV_ED = torch.sum((input_1['segment'][tio.DATA]==1).int(), (1,2,3,4)).float()\n",
        "  MYO_ED = torch.sum((input_1['segment'][tio.DATA]==2).int(), (1,2,3,4)).float()\n",
        "\n",
        "  vol_total = LV_ED+RV_ED+MYO_ED\n",
        "  LV_ED = LV_ED/vol_total\n",
        "  RV_ED = RV_ED/vol_total\n",
        "  MYO_ED = MYO_ED/vol_total\n",
        "\n",
        "  volume_ED_LV_test.append(LV_ED)\n",
        "  volume_ED_RV_test.append(RV_ED)\n",
        "  volume_ED_MYO_test.append(MYO_ED)\n",
        "\n",
        "  rat_RV_LV_ED_test.append(RV_ED/LV_ED)\n",
        "  rat_MYO_LV_ED_test.append(MYO_ED/LV_ED)\n",
        "\n",
        "\n",
        "\n",
        "  LV_ES = np.sum(test_masks_ES[i])\n",
        "  RV_ES = torch.sum((input_2['segment'][tio.DATA]==1).int(), (1,2,3,4)).float()\n",
        "  MYO_ES = torch.sum((input_2['segment'][tio.DATA]==2).int(), (1,2,3,4)).float()\n",
        "  vol_total = LV_ES+RV_ES+MYO_ES\n",
        "  LV_ES = LV_ES/vol_total\n",
        "  RV_ES = RV_ES/vol_total\n",
        "  MYO_ES = MYO_ES/vol_total\n",
        "\n",
        "  volume_ES_LV_test.append(LV_ES)\n",
        "  volume_ES_RV_test.append(RV_ES)\n",
        "  volume_ES_MYO_test.append(MYO_ES)\n",
        "\n",
        "  rat_RV_LV_ES_test.append(RV_ES/LV_ES)\n",
        "  rat_MYO_LV_ES_test.append(MYO_ES/LV_ES)\n",
        "\n",
        "\n",
        "  LV_ejection_test.append((LV_ES-LV_ED)/LV_ED)\n",
        "  RV_ejection_test.append((RV_ES-RV_ED)/RV_ED)\n",
        "\n",
        "  Vol_Change_LV_test.append((LV_ES-LV_ED))\n",
        "  Vol_Change_RV_test.append((RV_ES-RV_ED))\n",
        "\n",
        "\n",
        "  height_test.append(input_1['height'])\n",
        "  weight_test.append(input_1['weight'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMjXDlHF-hTL"
      },
      "outputs": [],
      "source": [
        "volume_ED_LV_test = np.concatenate(volume_ED_LV_test)[:, None]\n",
        "volume_ED_RV_test = np.concatenate(volume_ED_RV_test)[:, None]\n",
        "volume_ED_MYO_test = np.concatenate(volume_ED_MYO_test)[:, None]\n",
        "\n",
        "volume_ES_LV_test = np.concatenate(volume_ES_LV_test)[:, None]\n",
        "volume_ES_RV_test = np.concatenate(volume_ES_RV_test)[:, None]\n",
        "volume_ES_MYO_test = np.concatenate(volume_ES_MYO_test)[:, None]\n",
        "\n",
        "\n",
        "LV_ejection_test = np.concatenate(LV_ejection_test)[:, None]\n",
        "RV_ejection_test = np.concatenate(RV_ejection_test)[:, None]\n",
        "\n",
        "\n",
        "Vol_Change_LV_test = np.concatenate(Vol_Change_LV_test)[:, None]\n",
        "Vol_Change_RV_test = np.concatenate(Vol_Change_RV_test)[:, None]\n",
        "\n",
        "rat_RV_LV_ED_test = np.concatenate(rat_RV_LV_ED_test)[:, None]\n",
        "rat_RV_LV_ES_test = np.concatenate(rat_RV_LV_ES_test)[:, None]\n",
        "\n",
        "rat_MYO_LV_ED_test = np.concatenate(rat_MYO_LV_ED_test)[:, None]\n",
        "rat_MYO_LV_ES_test = np.concatenate(rat_MYO_LV_ES_test)[:, None]\n",
        "\n",
        "height_test = np.concatenate(height_test)[:, None]\n",
        "weight_test = np.concatenate(weight_test)[:, None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4ArE9Nj-mkn"
      },
      "outputs": [],
      "source": [
        "X_test = np.concatenate((volume_ED_LV_test,volume_ED_RV_test,\n",
        "                         volume_ED_MYO_test,volume_ES_LV_test,\n",
        "                         volume_ES_RV_test,volume_ES_MYO_test,\n",
        "                         LV_ejection_test,RV_ejection_test,\n",
        "                         Vol_Change_LV_test, Vol_Change_RV_test,\n",
        "                         rat_RV_LV_ED_test,rat_RV_LV_ES_test,\n",
        "                         rat_MYO_LV_ED_test,rat_MYO_LV_ES_test,\n",
        "                         test_ED_mean_thickness_MYO, test_ES_mean_thickness_MYO,\n",
        "                         test_ED_std_thickness_MYO, test_ES_std_thickness_MYO,\n",
        "                         test_ED_min_thickness_MYO, test_ES_min_thickness_MYO,\n",
        "                         test_ED_max_thickness_MYO, test_ES_max_thickness_MYO,\n",
        "                         test_ED_circular_MYO, test_ES_circular_MYO,\n",
        "                         test_ED_circumference_MYO, test_ES_circumference_MYO,\n",
        "                         height_test,weight_test), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLnhp20GBJIo"
      },
      "source": [
        "# training the models using theses primary obtained features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9a9W0O_BNK1",
        "outputId": "3e27bf6f-e538-4687-c18d-a01a38e5b527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Validation Score: 0.95\n",
            "Best params: {'random_state': 0}\n",
            "Random Forest test score : 1.0\n"
          ]
        }
      ],
      "source": [
        "RF=RandomForestClassifier(n_estimators=1000)\n",
        "p_grid_RF = {'random_state': [0,1,2,3,4,5]}\n",
        "\n",
        "grid_RF = GridSearchCV(estimator=RF, param_grid=p_grid_RF, scoring='accuracy', cv=5)\n",
        "grid_RF.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "\n",
        "print(\"Best Validation Score: {}\".format(grid_RF.best_score_))\n",
        "print(\"Best params: {}\".format(grid_RF.best_params_))\n",
        "print(\"Random Forest test score :\",grid_RF.score(X_train,np.ravel(y_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0nIIj8IjlDT",
        "outputId": "60dc49ec-8299-4fb5-b954-526da171dab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 4. 0. 3. 4. 1. 0. 3. 4. 4. 3. 3. 4. 0. 0. 4. 2. 3. 1. 0. 4. 0. 3. 3.\n",
            " 1. 2. 1. 4. 2. 4. 1. 4. 3. 2. 0. 3. 1. 3. 2. 0. 2. 2. 1. 2. 4. 2. 3. 1.\n",
            " 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "y_test = grid_RF.predict(X_test)\n",
        "print(y_test)\n",
        "data = []\n",
        "for i in range(101,151):\n",
        "  data.append([str(i), str(int(y_test[i-101]))])\n",
        "df = pd.DataFrame(data, columns=['Id', 'Category'])\n",
        "df.set_index('Id', inplace=True)\n",
        "df.to_csv(os.path.join(data_path, 'results', 'only_rf.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V69ST8exFiI_"
      },
      "source": [
        "# changing the training method to more complicated ones : ensemble of MLPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Nv3vHvB--v0"
      },
      "outputs": [],
      "source": [
        "# creating a dataloader from the extracted features\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FeatureDataset(Dataset):\n",
        "  def __init__(self, features, targets):\n",
        "    self.features = features\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.features[index], self.targets[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqSHs0wuPFpQ"
      },
      "outputs": [],
      "source": [
        "class GaussianNoise(nn.Module):\n",
        "    def __init__(self, std_dev):\n",
        "        super(GaussianNoise, self).__init__()\n",
        "        self.std_dev = std_dev\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            noise = torch.randn(x.size()) * self.std_dev\n",
        "            return x + noise\n",
        "        else:\n",
        "            return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJpNLW12-Oea"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Define MLP architecture\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(136, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.LeakyReLU(),\n",
        "            GaussianNoise(0.1),\n",
        "            nn.Linear(32, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.LeakyReLU(),\n",
        "            GaussianNoise(0.1),\n",
        "            nn.Linear(32, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.LeakyReLU(),\n",
        "            GaussianNoise(0.1),\n",
        "            nn.Linear(32, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.LeakyReLU(),\n",
        "            GaussianNoise(0.1),\n",
        "            nn.Linear(32, 5)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 136)\n",
        "        x = self.layers(x)\n",
        "        return x\n",
        "\n",
        "# Define training loop\n",
        "def train(model, input, target, criterion, optimizer, schedular):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    input = input.to(torch.float32)\n",
        "    target = target.type(torch.LongTensor)\n",
        "\n",
        "    outputs = model(input)\n",
        "    loss = criterion(outputs, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    #schedular.step()\n",
        "\n",
        "# Define validation loop\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(torch.float32)\n",
        "            labels = labels.type(torch.LongTensor)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            #print(predicted)\n",
        "            #print(labels)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Define validation loop\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            inputs = inputs.to(torch.float32)\n",
        "            labels.append(F.softmax(model(inputs),dim=1))\n",
        "\n",
        "\n",
        "    labels = torch.cat([*labels], dim=0)\n",
        "    return labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# running the following cell would take a huge amount of time. Instead, the trained models can be accessed from the link in the report (a link to a drive)"
      ],
      "metadata": {
        "id": "NRy0fhAr7MyL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Eq9wpCGSaFj",
        "outputId": "b261114a-c7d7-432e-a3bb-e105483dafb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  0  model is :  165  with an accuracy of  1.0\n",
            "initial accuracy  0.76\n",
            "current best accuracy  0.76\n",
            "current best accuracy  0.76\n",
            "current best accuracy  0.76\n",
            "current best accuracy  0.76\n",
            "current best accuracy  0.76\n",
            "current best accuracy  0.76\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "the best epoch for the  1  model is :  381  with an accuracy of  0.92\n",
            "initial accuracy  0.76\n",
            "current best accuracy  0.76\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  2  model is :  160  with an accuracy of  1.0\n",
            "initial accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "the best epoch for the  3  model is :  241  with an accuracy of  0.88\n",
            "initial accuracy  0.72\n",
            "current best accuracy  0.72\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "the best epoch for the  4  model is :  218  with an accuracy of  0.92\n",
            "initial accuracy  0.76\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "the best epoch for the  5  model is :  387  with an accuracy of  0.92\n",
            "initial accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "the best epoch for the  6  model is :  281  with an accuracy of  0.92\n",
            "initial accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "the best epoch for the  7  model is :  314  with an accuracy of  0.96\n",
            "initial accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "the best epoch for the  8  model is :  386  with an accuracy of  0.96\n",
            "initial accuracy  0.68\n",
            "current best accuracy  0.68\n",
            "current best accuracy  0.72\n",
            "current best accuracy  0.72\n",
            "current best accuracy  0.72\n",
            "current best accuracy  0.72\n",
            "current best accuracy  0.72\n",
            "current best accuracy  0.72\n",
            "current best accuracy  0.76\n",
            "current best accuracy  0.76\n",
            "current best accuracy  0.76\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "the best epoch for the  9  model is :  145  with an accuracy of  0.88\n",
            "initial accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  10  model is :  238  with an accuracy of  1.0\n",
            "initial accuracy  0.88\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  11  model is :  270  with an accuracy of  1.0\n",
            "initial accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "the best epoch for the  12  model is :  323  with an accuracy of  0.96\n",
            "initial accuracy  0.76\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "the best epoch for the  13  model is :  283  with an accuracy of  0.96\n",
            "initial accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  14  model is :  220  with an accuracy of  1.0\n",
            "initial accuracy  0.8\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "the best epoch for the  15  model is :  85  with an accuracy of  0.96\n",
            "initial accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  16  model is :  185  with an accuracy of  1.0\n",
            "initial accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  17  model is :  394  with an accuracy of  1.0\n",
            "initial accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  18  model is :  398  with an accuracy of  1.0\n",
            "initial accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "the best epoch for the  19  model is :  204  with an accuracy of  0.96\n",
            "initial accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  20  model is :  399  with an accuracy of  1.0\n",
            "initial accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "the best epoch for the  21  model is :  366  with an accuracy of  0.96\n",
            "initial accuracy  0.72\n",
            "current best accuracy  0.72\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "the best epoch for the  22  model is :  308  with an accuracy of  0.96\n",
            "initial accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "the best epoch for the  23  model is :  356  with an accuracy of  0.96\n",
            "initial accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "the best epoch for the  24  model is :  320  with an accuracy of  0.96\n",
            "initial accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  25  model is :  27  with an accuracy of  1.0\n",
            "initial accuracy  0.84\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  26  model is :  383  with an accuracy of  1.0\n",
            "initial accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "the best epoch for the  27  model is :  145  with an accuracy of  0.92\n",
            "initial accuracy  0.8\n",
            "current best accuracy  0.8\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.84\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  0.92\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  28  model is :  105  with an accuracy of  1.0\n",
            "initial accuracy  0.88\n",
            "current best accuracy  0.88\n",
            "current best accuracy  0.96\n",
            "current best accuracy  0.96\n",
            "current best accuracy  1.0\n",
            "the best epoch for the  29  model is :  7  with an accuracy of  1.0\n"
          ]
        }
      ],
      "source": [
        "# Set up ensemble\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "standard = StandardScaler()\n",
        "standard.fit(X_train)\n",
        "X_train_standard=standard.transform(X_train)\n",
        "X_test_standard=standard.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "ensemble_size = 30\n",
        "ensemble = [MLP() for _ in range(ensemble_size)]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizers = [optim.Adam(ensemble[i].parameters(), lr=0.0005) for i in range(ensemble_size)]\n",
        "schedulers = [optim.lr_scheduler.ExponentialLR(optimizers[i], gamma=0.97) for i in range(ensemble_size)]\n",
        "\n",
        "\n",
        "num_epochs = 400\n",
        "best_models = []\n",
        "chosen_indices_feats = []\n",
        "for model_idx in range(ensemble_size):\n",
        "\n",
        "  # An epoch is defined as a set of 50 batches containing 20 patients each.\n",
        "  batch_size = 20\n",
        "  n_sets_in_epoch = 50\n",
        "  current_model = ensemble[model_idx]\n",
        "  current_opt = optimizers[model_idx]\n",
        "  current_sch = schedulers[model_idx]\n",
        "\n",
        "  # !choosing only 90 features to train on\n",
        "\n",
        "  #indices_feats = list(range(X_train.shape[1]))\n",
        "  #np.random.shuffle(indices_feats)\n",
        "  #indices_feats = indices_feats[:]\n",
        "  current_X_train = X_train_standard\n",
        "\n",
        "  #chosen_indices_feats.append(indices_feats)\n",
        "\n",
        "\n",
        "\n",
        "  indices = list(range(len(current_X_train)))\n",
        "  np.random.shuffle(indices)\n",
        "  train_length = int(len(current_X_train)*0.75)\n",
        "\n",
        "  train_feats = current_X_train[indices][:train_length]\n",
        "  train_labels = y_train[indices][:train_length]\n",
        "\n",
        "  val_feats = current_X_train[indices][train_length:]\n",
        "  val_labels = y_train[indices][train_length:]\n",
        "\n",
        "  current_train_dataset = FeatureDataset(train_feats,train_labels)\n",
        "  current_val_dataset = FeatureDataset(val_feats,val_labels)\n",
        "\n",
        "  # creating dataloaders from feats\n",
        "  train_dataloader = DataLoader(current_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  val_dataloader = DataLoader(current_val_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "  for n_epoch in range(num_epochs):\n",
        "\n",
        "    for n_set in range(n_sets_in_epoch):\n",
        "\n",
        "      for input, target in train_dataloader:\n",
        "\n",
        "        train(current_model, input, target, criterion, current_opt, current_sch)\n",
        "\n",
        "\n",
        "\n",
        "    # epoch selection\n",
        "    if n_epoch==0:\n",
        "      best_acc = validate(current_model, val_dataloader, criterion)\n",
        "      best_model = copy.copy(current_model)\n",
        "      best_idx = 0\n",
        "      print('initial accuracy ', best_acc)\n",
        "    else:\n",
        "\n",
        "      current_acc = validate(current_model, val_dataloader, criterion)\n",
        "      if current_acc >= best_acc:\n",
        "        best_acc = current_acc\n",
        "        best_model = copy.copy(current_model)\n",
        "        best_idx = n_epoch\n",
        "        print('current best accuracy ', best_acc)\n",
        "\n",
        "  print('the best epoch for the ', model_idx, ' model is : ', best_idx, ' with an accuracy of ', best_acc)\n",
        "  best_models.append(best_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFnwqeeX0uA3"
      },
      "outputs": [],
      "source": [
        "# writing the trained models down\n",
        "for i in range(ensemble_size):\n",
        "  current_path = os.path.join(data_path, 'best_models', 'classifier'+str(i)+'.pt')\n",
        "  torch.save(best_models[i].state_dict(), current_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H1y4tv7E-U4"
      },
      "outputs": [],
      "source": [
        "# the models are trained with different permutations of features\n",
        "# (because before I was trying to just pick 90 features out of 136, and this is for compatibility reasons)\n",
        "\n",
        "data = []\n",
        "\n",
        "for i in range(ensemble_size):\n",
        "  data.append(chosen_indices_feats[i])\n",
        "\n",
        "columns = [str(i) for i in range(136)]\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "df.to_csv(os.path.join(data_path, 'best_models', 'features.txt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# the commands to run to retrieve the trained models and combinations of features"
      ],
      "metadata": {
        "id": "d-TUnyKVIGCY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRUYcUvlB9Zi"
      },
      "outputs": [],
      "source": [
        "# loading back the saved models\n",
        "ensemble_size = 30\n",
        "best_models_regul = []\n",
        "for i in range(ensemble_size):\n",
        "  model_save_name = os.path.join(data_path, 'best_models', 'classifier'+str(i)+'.pt')\n",
        "  current_model = MLP()\n",
        "  current_model.load_state_dict(torch.load(model_save_name))\n",
        "  best_models_regul.append(current_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_feats_df = pd.read_csv(os.path.join(data_path, 'best_models', 'features.txt'))\n",
        "chosen_feats = []\n",
        "for i in range(ensemble_size):\n",
        "  chosen_feats.append(np.array(chosen_feats_df.loc[i])[1:])\n"
      ],
      "metadata": {
        "id": "bGf8gAtMIu4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8ct2I3v-YYi"
      },
      "source": [
        "# Using the models to aggregate scores for different classes\n",
        "# And evaluate the performance on the whole train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laOXZsg4EbeY",
        "outputId": "64390ae2-64d1-49a5-930a-b01c34e6ee49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 3, 4, 4, 2, 4, 1, 0, 1, 1, 2, 0, 1, 1, 0, 2, 2, 0, 2, 1, 3, 4, 2, 1,\n",
            "        2, 4, 1, 1, 0, 3, 3, 3, 0, 2, 1, 0, 1, 4, 3, 4, 3, 3, 3, 2, 3, 4, 1, 3,\n",
            "        0, 2, 1, 0, 3, 3, 3, 0, 1, 2, 4, 0, 4, 2, 0, 2, 4, 4, 1, 0, 4, 1, 0, 3,\n",
            "        0, 2, 2, 3, 2, 1, 1, 3, 0, 4, 0, 2, 0, 4, 4, 3, 1, 2, 4, 3, 2, 3, 0, 4,\n",
            "        0, 2, 1, 4])\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "batch_size=10\n",
        "\n",
        "standard = StandardScaler()\n",
        "standard.fit(X_train)\n",
        "X_train_standard=standard.transform(X_train)\n",
        "\n",
        "y_ensemble = torch.zeros((100, 5))\n",
        "for i in range(ensemble_size):\n",
        "\n",
        "\n",
        "  #print(np.array(X_train[:,np.array(chosen_feats[i]).reshape(-1)]).shape)\n",
        "  train_dataset = FeatureDataset(X_train_standard,y_train)\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "  y = test(best_models[i], train_dataloader)\n",
        "  y_ensemble += y\n",
        "\n",
        "\n",
        "y_ensemble_chosen = torch.argmax(y_ensemble, dim=1)\n",
        "print(y_ensemble_chosen)\n",
        "y_ensemble_chosen = y_ensemble_chosen.cpu().numpy()\n",
        "print((y_ensemble_chosen == y_train).sum().item()/100.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIbseM0ZEjwm"
      },
      "source": [
        "# Testing the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27Fa1jXXH0Zf",
        "outputId": "1b06b57e-1747-4d0b-841e-02117c76bdd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 4 0 3 4 1 0 0 4 0 3 3 0 0 0 4 2 3 1 0 4 0 3 3 1 2 1 4 2 4 1 4 0 2 0 3 2\n",
            " 3 2 0 2 2 1 2 4 2 0 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "batch_size=10\n",
        "\n",
        "X_test_standard=standard.transform(X_test)\n",
        "\n",
        "\n",
        "y_ensemble = torch.zeros((50, 5))\n",
        "for i in range(ensemble_size):\n",
        "\n",
        "\n",
        "  #print(np.array(X_train[:,np.array(chosen_feats[i]).reshape(-1)]).shape)\n",
        "  test_dataset = FeatureDataset(X_test_standard,np.zeros(X_test.shape[0]))\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "  y = test(best_models[i], test_dataloader)\n",
        "  y_ensemble += y\n",
        "\n",
        "\n",
        "y_ensemble_chosen = torch.argmax(y_ensemble, dim=1)\n",
        "y_ensemble_chosen = y_ensemble_chosen.cpu().numpy()\n",
        "\n",
        "\n",
        "print(y_ensemble_chosen)\n",
        "\n",
        "\n",
        "\n",
        "data = []\n",
        "\n",
        "for i in range(101,151):\n",
        "  data.append([str(i), str(int(y_ensemble_chosen[i-101]))])\n",
        "df = pd.DataFrame(data, columns=['Id', 'Category'])\n",
        "df.set_index('Id', inplace=True)\n",
        "#print(df)\n",
        "df.to_csv(os.path.join(data_path, 'results', '26_April_1.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA1s0tKSGkgr"
      },
      "source": [
        "# Let us combine the deep models with the random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQdEofYxG8nV",
        "outputId": "b2132354-e135-4b52-8197-dec6638ce3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest test score : 1.0\n",
            "Random Forest test score : 1.0\n",
            "Random Forest test score : 1.0\n"
          ]
        }
      ],
      "source": [
        "# This is the golden estimator!! found it!! found it!!\n",
        "RF1=RandomForestClassifier(random_state=2, n_estimators=1000)\n",
        "RF2=RandomForestClassifier(random_state=1, n_estimators=1000)\n",
        "RF3=RandomForestClassifier(random_state=0, n_estimators=1000)\n",
        "\n",
        "RF1.fit(X_train, np.ravel(y_train))\n",
        "RF2.fit(X_train, np.ravel(y_train))\n",
        "RF3.fit(X_train, np.ravel(y_train))\n",
        "\n",
        "print(\"Random Forest test score :\",RF1.score(X_train,np.ravel(y_train)))\n",
        "print(\"Random Forest test score :\",RF2.score(X_train,np.ravel(y_train)))\n",
        "print(\"Random Forest test score :\",RF3.score(X_train,np.ravel(y_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XiF6jAEHEtT",
        "outputId": "4cc284ab-8893-4d59-e42a-6b71b08efb94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 4 0 3 4 1 0 0 4 0 3 3 0 0 0 4 2 3 1 0 4 0 3 3 1 2 1 4 2 4 1 4 0 2 0 3 2\n",
            " 3 2 0 2 2 1 2 4 2 0 1 1 1]\n",
            "tensor(1499.9999)\n",
            "tensor(2550.0000, dtype=torch.float64)\n",
            "[2 4 0 3 4 1 0 3 4 4 3 3 4 0 0 4 2 3 1 0 4 0 3 3 1 2 1 4 2 4 1 4 3 2 0 3 2\n",
            " 3 2 0 2 2 1 2 4 2 0 1 1 1]\n",
            "    Category\n",
            "Id          \n",
            "101        2\n",
            "102        4\n",
            "103        0\n",
            "104        3\n",
            "105        4\n",
            "106        1\n",
            "107        0\n",
            "108        3\n",
            "109        4\n",
            "110        4\n",
            "111        3\n",
            "112        3\n",
            "113        4\n",
            "114        0\n",
            "115        0\n",
            "116        4\n",
            "117        2\n",
            "118        3\n",
            "119        1\n",
            "120        0\n",
            "121        4\n",
            "122        0\n",
            "123        3\n",
            "124        3\n",
            "125        1\n",
            "126        2\n",
            "127        1\n",
            "128        4\n",
            "129        2\n",
            "130        4\n",
            "131        1\n",
            "132        4\n",
            "133        3\n",
            "134        2\n",
            "135        0\n",
            "136        3\n",
            "137        2\n",
            "138        3\n",
            "139        2\n",
            "140        0\n",
            "141        2\n",
            "142        2\n",
            "143        1\n",
            "144        2\n",
            "145        4\n",
            "146        2\n",
            "147        0\n",
            "148        1\n",
            "149        1\n",
            "150        1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "y_test1 = RF1.predict(X_test)\n",
        "encoder = OneHotEncoder(categories='auto', sparse=False)\n",
        "y_test1 = y_test1.reshape(-1, 1)\n",
        "y_test_one_hot1 = encoder.fit_transform(y_test1)*7\n",
        "\n",
        "y_test2 = RF2.predict(X_test)\n",
        "y_test2 = y_test2.reshape(-1, 1)\n",
        "y_test_one_hot2 = encoder.fit_transform(y_test2)*7\n",
        "\n",
        "\n",
        "y_test3 = RF3.predict(X_test)\n",
        "y_test3 = y_test3.reshape(-1, 1)\n",
        "y_test_one_hot3 = encoder.fit_transform(y_test3)*7\n",
        "\n",
        "\n",
        "X_test_standard=standard.transform(X_test)\n",
        "\n",
        "\n",
        "y_ensemble = torch.zeros((50, 5))\n",
        "for i in range(ensemble_size):\n",
        "\n",
        "\n",
        "  #print(np.array(X_train[:,np.array(chosen_feats[i]).reshape(-1)]).shape)\n",
        "  test_dataset = FeatureDataset(X_test_standard,np.zeros(X_test.shape[0]))\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "  y = test(best_models[i], test_dataloader)\n",
        "  y_ensemble += y\n",
        "\n",
        "\n",
        "y_ensemble_chosen = torch.argmax(y_ensemble, dim=1)\n",
        "y_ensemble_chosen = y_ensemble_chosen.cpu().numpy()\n",
        "\n",
        "\n",
        "print(y_ensemble_chosen)\n",
        "\n",
        "\n",
        "\n",
        "print(y_ensemble.sum())\n",
        "y_ensemble += y_test_one_hot1\n",
        "y_ensemble += y_test_one_hot2\n",
        "y_ensemble += y_test_one_hot3\n",
        "print(y_ensemble.sum())\n",
        "y_ensemble_chosen = torch.argmax(y_ensemble, dim=1)\n",
        "y_ensemble_chosen = y_ensemble_chosen.cpu().numpy()\n",
        "print(y_ensemble_chosen)\n",
        "\n",
        "data = []\n",
        "\n",
        "for i in range(101,151):\n",
        "  data.append([str(i), str(int(y_ensemble_chosen[i-101]))])\n",
        "df = pd.DataFrame(data, columns=['Id', 'Category'])\n",
        "df.set_index('Id', inplace=True)\n",
        "print(df)\n",
        "df.to_csv(os.path.join(data_path, 'results', '26_April_4.csv'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}